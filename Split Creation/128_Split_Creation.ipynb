{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def create_unique_splits(df, train_size=128, val_size=128, test_size=10000):\n",
    "    # Ensure the dataset is large enough\n",
    "    if len(df) < train_size + val_size + test_size:\n",
    "        raise ValueError(\"Dataset is too small to create the requested splits.\")\n",
    "    \n",
    "    # Shuffle the dataset\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # Initialize empty DataFrames for each split\n",
    "    train_df = pd.DataFrame(columns=df.columns)\n",
    "    val_df = pd.DataFrame(columns=df.columns)\n",
    "    test_df = pd.DataFrame(columns=df.columns)\n",
    "    \n",
    "    # Track used IDs to ensure uniqueness\n",
    "    used_subject_ids = set()\n",
    "    used_study_ids = set()\n",
    "    used_labevent_ids = set()\n",
    "    \n",
    "    # Function to check if a row is unique\n",
    "    def is_unique(row):\n",
    "        return (row['subject_id'] not in used_subject_ids and\n",
    "                row['study_id'] not in used_study_ids and\n",
    "                row['labevent_id'] not in used_labevent_ids)\n",
    "    \n",
    "    # Function to add a row to a split and mark its IDs as used\n",
    "    def add_to_split(split_df, row):\n",
    "        split_df.loc[len(split_df)] = row\n",
    "        used_subject_ids.add(row['subject_id'])\n",
    "        used_study_ids.add(row['study_id'])\n",
    "        used_labevent_ids.add(row['labevent_id'])\n",
    "    \n",
    "    # Iterate through the dataset and assign rows to splits\n",
    "    for _, row in df.iterrows():\n",
    "        if is_unique(row):\n",
    "            if len(train_df) < train_size:\n",
    "                add_to_split(train_df, row)\n",
    "            elif len(val_df) < val_size:\n",
    "                add_to_split(val_df, row)\n",
    "            elif len(test_df) < test_size:\n",
    "                add_to_split(test_df, row)\n",
    "            else:\n",
    "                break  # All splits are filled\n",
    "    \n",
    "    # Check if all splits are filled\n",
    "    if len(train_df) < train_size or len(val_df) < val_size or len(test_df) < test_size:\n",
    "        raise ValueError(\"Could not create splits with unique IDs. Dataset may have overlapping IDs.\")\n",
    "    \n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Volumes/SanDisk SSD/physionet.org/files/mimic-iv-ecg/1.0/MIMIC-IV-ECG-Ext-Electrolytes/\"\n",
    "\n",
    "# Process for Calcium50893\n",
    "df = pd.read_csv(path + \"mimiciv_ECGv1.1_hospV2.2_Calcium50893.csv\")\n",
    "train_df, val_df, test_df = create_unique_splits(df)\n",
    "calcium50893_df = pd.concat([train_df[['subject_id', 'study_id', 'labevent_id']],\n",
    "                             val_df[['subject_id', 'study_id', 'labevent_id']],\n",
    "                             test_df[['subject_id', 'study_id', 'labevent_id']]])\n",
    "\n",
    "calcium50893_df['split'] = ['train'] * len(train_df) + ['val'] * len(val_df) + ['test'] * len(test_df)\n",
    "calcium50893_df.to_csv(path + \"few_shot_splits/128shots/split1/Calcium50893.csv\", index=False)\n",
    "\n",
    "# Process for Creatinine50912\n",
    "df = pd.read_csv(path + \"mimiciv_ECGv1.1_hospV2.2_Creatinine50912.csv\")\n",
    "train_df, val_df, test_df = create_unique_splits(df)\n",
    "creatinine50912_df = pd.concat([train_df[['subject_id', 'study_id', 'labevent_id']],\n",
    "                                 val_df[['subject_id', 'study_id', 'labevent_id']],\n",
    "                                 test_df[['subject_id', 'study_id', 'labevent_id']]])\n",
    "creatinine50912_df['split'] = ['train'] * len(train_df) + ['val'] * len(val_df) + ['test'] * len(test_df)\n",
    "creatinine50912_df.to_csv(path + \"few_shot_splits/128shots/split1/Creatinine50912.csv\", index=False)\n",
    "\n",
    "# Process for Magnesium50960\n",
    "df = pd.read_csv(path + \"mimiciv_ECGv1.1_hospV2.2_Magnesium50960.csv\")\n",
    "train_df, val_df, test_df = create_unique_splits(df)\n",
    "magnesium50960_df = pd.concat([train_df[['subject_id', 'study_id', 'labevent_id']],\n",
    "                                val_df[['subject_id', 'study_id', 'labevent_id']],\n",
    "                                test_df[['subject_id', 'study_id', 'labevent_id']]])\n",
    "magnesium50960_df['split'] = ['train'] * len(train_df) + ['val'] * len(val_df) + ['test'] * len(test_df)\n",
    "magnesium50960_df.to_csv(path + \"few_shot_splits/128shots/split1/Magnesium50960.csv\", index=False)\n",
    "\n",
    "# Process for Potassium50971\n",
    "df = pd.read_csv(path + \"mimiciv_ECGv1.1_hospV2.2_Potassium50971.csv\")\n",
    "train_df, val_df, test_df = create_unique_splits(df)\n",
    "potassium50971_df = pd.concat([train_df[['subject_id', 'study_id', 'labevent_id']],\n",
    "                                val_df[['subject_id', 'study_id', 'labevent_id']],\n",
    "                                test_df[['subject_id', 'study_id', 'labevent_id']]])\n",
    "potassium50971_df['split'] = ['train'] * len(train_df) + ['val'] * len(val_df) + ['test'] * len(test_df)\n",
    "potassium50971_df.to_csv(path + \"few_shot_splits/128shots/split1/Potassium50971.csv\", index=False)\n",
    "\n",
    "# Process for Sodium50983\n",
    "df = pd.read_csv(path + \"mimiciv_ECGv1.1_hospV2.2_Sodium50983.csv\")\n",
    "train_df, val_df, test_df = create_unique_splits(df)\n",
    "sodium50983_df = pd.concat([train_df[['subject_id', 'study_id', 'labevent_id']],\n",
    "                             val_df[['subject_id', 'study_id', 'labevent_id']],\n",
    "                             test_df[['subject_id', 'study_id', 'labevent_id']]])\n",
    "sodium50983_df['split'] = ['train'] * len(train_df) + ['val'] * len(val_df) + ['test'] * len(test_df)\n",
    "sodium50983_df.to_csv(path + \"few_shot_splits/128shots/split1/Sodium50983.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
